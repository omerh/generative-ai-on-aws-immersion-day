{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisite  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -q boto3 langchain sagemaker-studio-image-build aws-sam-cli"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"gen-ai-workshop\"\n",
    "jumpstart_model = \"huggingface-llm-falcon-7b-instruct-bf16\"\n",
    "endpoint_name=f\"{name}-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "aws_account_id = boto3.client('sts').get_caller_identity().get('Account')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Kendra Index\n",
    "\n",
    "Kendra will be the RAG endpoint, that will store our documents, for RAG prompt engineering.\n",
    "\n",
    "We will first create a role for Kendra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "kendra_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\n",
    "        \"Effect\": \"Allow\",\n",
    "        \"Principal\": {\n",
    "            \"Service\": \"kendra.amazonaws.com\"\n",
    "        },\n",
    "        \"Action\": \"sts:AssumeRole\"\n",
    "        }]\n",
    "    }\n",
    "\n",
    "policy_cloudwatch_arn = \"arn:aws:iam::aws:policy/CloudWatchLogsFullAccess\"\n",
    "\n",
    "try:\n",
    "    response =iam_client.get_role(RoleName=f\"kendra-{name}-role\")\n",
    "    print(f\"kendra-{name}-role Role already exists\")\n",
    "except:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=f\"kendra-{name}-role\",\n",
    "        AssumeRolePolicyDocument=json.dumps(kendra_trust_policy),\n",
    "    )\n",
    "    print(f\"Created the role kendra-{name}-role\")\n",
    "    \n",
    "kendra_role_arn = response[\"Role\"][\"Arn\"]\n",
    "\n",
    "try:\n",
    "    response = iam_client.attach_role_policy(\n",
    "        RoleName=f\"kendra-{name}-role\",\n",
    "        PolicyArn=policy_cloudwatch_arn\n",
    "    )\n",
    "except:\n",
    "    print(f\"Policy already attached to role kendra-{name}-role\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27e4dd85-0cd8-4d6c-8b63-5f439790007f\n"
     ]
    }
   ],
   "source": [
    "kendra_client = boto3.client(\"kendra\")\n",
    "\n",
    "def list_kendra_indices(kendra_client):\n",
    "    kendra_indices = kendra_client.list_indices()\n",
    "    return kendra_indices[\"IndexConfigurationSummaryItems\"]\n",
    "\n",
    "\n",
    "def find_index_id_according_to_tag(kendra_client, indices, aws_region, aws_account_id):\n",
    "    for k_index in indices:\n",
    "        describe_index_tags_response = kendra_client.list_tags_for_resource(\n",
    "            ResourceARN=f\"arn:aws:kendra:{aws_region}:{aws_account_id}:index/{k_index['Id']}\"\n",
    "        )\n",
    "        for tag in describe_index_tags_response[\"Tags\"]:\n",
    "            if tag[\"Key\"] == \"workshop\" and tag[\"Value\"] == \"gen-ai\":\n",
    "                return k_index['Id']\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_kendra_index(kendra_client):\n",
    "    kendra_index_response = kendra_client.create_index(\n",
    "        Name=f\"{name}-index\",\n",
    "        Edition=\"DEVELOPER_EDITION\",\n",
    "        RoleArn=kendra_role_arn,\n",
    "        Tags=[{\n",
    "            'Key': 'workshop',\n",
    "            'Value': 'gen-ai'\n",
    "            }]\n",
    "    )\n",
    "    kendra_index_id = kendra_index_response[\"Id\"]\n",
    "    return kendra_index_id\n",
    "\n",
    "\n",
    "# Creating Kendra index\n",
    "kendra_indices = list_kendra_indices(kendra_client)\n",
    "if len(kendra_indices) > 0:\n",
    "    kendra_index_id = find_index_id_according_to_tag(kendra_client, kendra_indices, aws_region, aws_account_id)\n",
    "    if kendra_index_id is None:\n",
    "        # you have indices but not tagged with workshop=gen-ai\n",
    "        kendra_index_id = create_kendra_index(kendra_client)\n",
    "else:\n",
    "    create_kendra_index(kendra_client)\n",
    "\n",
    "\n",
    "print(kendra_index_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Endpoint provisioning\n",
    "\n",
    "Now we will deploy LLM Model Falcon 7B instruct using SageMaker sdk `JumpstartModel` class, that will do all the heavy lifting configuring the endpoint in Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "try:\n",
    "    sm_execution_role = get_execution_role()\n",
    "except:\n",
    "    # To work locally use explicit role\n",
    "    sm_execution_role = \"arn:aws:iam::910416587115:role/SageMaker-Role-Full\"\n",
    "\n",
    "print(sm_execution_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "\n",
    "jumpstart_model_id = \"huggingface-textgeneration-falcon-7b-instruct-bf16\"\n",
    "sagemaker_endpoint_name = f\"{name}-falcon-7b-instruct\"\n",
    "\n",
    "\n",
    "try:\n",
    "    model = JumpStartModel(model_id=jumpstart_model_id, role=sm_execution_role)\n",
    "    model.deploy(endpoint_name=f\"{name}-falcon-7b-instruct-1\", wait=False)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"\"\"\\nPlease make sure that you dont have in your account an endpoint or endpoint configuration with name {sagemaker_endpoint_name}\\n\n",
    "          Endpoint configuration: Check at https://{aws_region}.console.aws.amazon.com/sagemaker/home?region={aws_region}#/endpointConfig\n",
    "          Endpoint: Check at https://{aws_region}.console.aws.amazon.com/sagemaker/home?region={aws_region}#/endpoints/ \n",
    "          \n",
    "          If the endpoint is already running, you may continue the workshop and use it.\n",
    "          \"\"\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the backend lambda, and API Gateway\n",
    "\n",
    "By now, we have launch Amazon Kendra, and Falcon LLM, using Amazon SageMaker endpoint.\n",
    "\n",
    "Now we will build the Backend lambda, using [AWS Serverless Application Model](https://aws.amazon.com/serverless/sam/) (SAM), an open-source framework for building serverless applications.\n",
    "\n",
    "The lambda code [rag_app](/lab4/rag_app/) contains couple of environment variables that help us control the lambda behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the container image for frontend chatbot application\n",
    "\n",
    "While using Sagemaker studio, using `sagemaker-studio-image-build` we can trigger a docker build leveraging [AWS CodeBuild](https://aws.amazon.com/codebuild/)\n",
    "\n",
    "We will start by adding appropriate roles to SageMaker execution role, to allow triggering the build job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sm_execution_role_name = sm_execution_role.split(\"/\")[-1]\n",
    "\n",
    "with open(\"codebuild-policy.json\") as f:\n",
    "    code_build_policy_document = f.read()\n",
    "\n",
    "iam_client = boto3.client(\"iam\")\n",
    "\n",
    "try:\n",
    "    policy_response = iam_client.create_policy(\n",
    "        PolicyName=f\"codebuild-policy-sm-docker-build\",\n",
    "        PolicyDocument=code_build_policy_document\n",
    "    )\n",
    "    code_build_policy_arn = policy_response['Policy']['Arn']\n",
    "except:\n",
    "    print(\"Policy exists\")\n",
    "    code_build_policy_arn = f\"arn:aws:iam::{aws_account_id}:policy/codebuild-policy-sm-docker-build\"\n",
    "    \n",
    "\n",
    "attach_response = iam_client.attach_role_policy(\n",
    "    RoleName=sm_execution_role_name,\n",
    "    PolicyArn=code_build_policy_arn\n",
    ")\n",
    "\n",
    "codebuild_trust_policy = {\n",
    "     \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"sagemaker.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": [\n",
    "                    \"codebuild.amazonaws.com\" \n",
    "                ]\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = iam_client.update_assume_role_policy(\n",
    "    RoleName=sm_execution_role_name,\n",
    "    PolicyDocument=json.dumps(codebuild_trust_policy)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have configured SageMaker execution role, we can trigger a build job to build the frontend chatbot application that was built using [`streamlit`](https://streamlit.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd fe && sm-docker build --role $sm_execution_role_name --repository gen-ai-streamlit-fe:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have updated the template file lets verify that all the components are ready, and deploy the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def is_kendra_active(kendra_index_id):\n",
    "    kendra_client = boto3.client('kendra')\n",
    "    response = kendra_client.describe_index(\n",
    "        Id=kendra_index_id\n",
    "    )\n",
    "    return response['Status']\n",
    "\n",
    "def is_sagemaker_jumpstart_active(sagemaker_endpoint_name):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    response = sagemaker_client.describe_endpoint(\n",
    "        EndpointName=sagemaker_endpoint_name\n",
    "    )\n",
    "    return response['EndpointStatus']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if Kendra index id 27e4dd85-0cd8-4d6c-8b63-5f439790007f is active\n",
      "Kendra index is ACTIVE\n",
      "Checking if Kendra index id gen-ai-workshop-falcon-7b-instruct is in service\n",
      "SageMaker endpoint is InService\n"
     ]
    }
   ],
   "source": [
    "print(f\"Checking if Kendra index id {kendra_index_id} is active\")\n",
    "while True:\n",
    "    try:\n",
    "        kendra_status = is_kendra_active(kendra_index_id)\n",
    "        if kendra_status == \"ACTIVE\":\n",
    "            print(f\"Kendra index is {kendra_status}\")\n",
    "            break\n",
    "        else:\n",
    "            system.stdout.write(\".\")\n",
    "            sleep(5)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Please check if you have an index in Kendra https://{aws_region}.console.aws.amazon.com/kendra/home?region={aws_region}#indexes\\n\")\n",
    "            break\n",
    "        \n",
    "\n",
    "print(f\"Checking if Kendra index id {sagemaker_endpoint_name} is in service\")\n",
    "while True:\n",
    "    try:\n",
    "        sagemaker_endpoint_status = is_sagemaker_jumpstart_active(sagemaker_endpoint_name)\n",
    "        if sagemaker_endpoint_status == \"InService\":\n",
    "            print(f\"SageMaker endpoint is {sagemaker_endpoint_status}\")\n",
    "            break\n",
    "        else:\n",
    "            system.stdout.write(\".\")\n",
    "            sleep(5)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Please check if you have a Sagemaker endpoint in SageMaker https://{aws_region}.console.aws.amazon.com/sagemaker/home?region={aws_region}#/endpoints\\n\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will update the [template](/lab4/template.yml), and deploy the stack using sam-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"template.yml\", 'r') as f:\n",
    "    template = f.read()\n",
    "    \n",
    "update_template = template.replace(\"***KENDRA_INDEX_ID***\", f\"{kendra_index_id}\")\n",
    "\n",
    "with open(\"template.yml\", 'w') as f:\n",
    "    f.write(update_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building codeuri:                                                               \n",
      "\u001b[35m/Users/omerhaim/work/aws/generative-ai-on-aws-immersion-day/lab4/\u001b[0m\u001b[95mrag_app\u001b[0m        \n",
      "runtime: python3.\u001b[1;36m10\u001b[0m metadata: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m architecture: x86_64 functions: RagAppFunction \n",
      "Running PythonPipBuilder:ResolveDependencies                                    \n",
      "Running PythonPipBuilder:CopySource                                             \n",
      "\u001b[32m\n",
      "Build Succeeded\u001b[0m\n",
      "\u001b[33m\n",
      "Built Artifacts  : .aws-sam/build\n",
      "Built Template   : .aws-sam/build/template.yaml\n",
      "\n",
      "Commands you can use next\n",
      "=========================\n",
      "[*] Validate SAM template: sam validate\n",
      "[*] Invoke Function: sam local invoke\n",
      "[*] Test Function in the Cloud: sam sync --stack-name {{stack-name}} --watch\n",
      "[*] Deploy: sam deploy --guided\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sam build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\tManaged S3 bucket: aws-sam-cli-managed-default-samclisourcebucket-ppxavannbzh9\n",
      "\t\tA different default S3 bucket can be set in samconfig.toml\n",
      "\t\tOr by specifying --s3-bucket explicitly.\n",
      "\tUploading to 8e0f8ed517fad6bc8357e78ee4ba13af  39920905 / 39920905  (100.00%)\n",
      "\u001b[33m\n",
      "\tDeploying with following values\n",
      "\t===============================\u001b[0m\n",
      "\tStack name                   : gen-ai-immersion-day-stack\n",
      "\tRegion                       : eu-west-1\n",
      "\tConfirm changeset            : False\n",
      "\tDisable rollback             : False\n",
      "\tDeployment s3 bucket         : aws-sam-cli-managed-default-samclisourcebucket-ppxavannbzh9\n",
      "\tCapabilities                 : [\"CAPABILITY_IAM\"]\n",
      "\tParameter overrides          : {}\n",
      "\tSigning Profiles             : {}\n",
      "\u001b[33m\n",
      "Initiating deployment\n",
      "=====================\n",
      "\u001b[0m\n",
      "\tUploading to cbb11184a07d3aff2b088bcd393c7510.template  9825 / 9825  (100.00%)\n",
      "\n",
      "\n",
      "Waiting for changeset to be created..\n",
      "\n",
      "\u001b[1mCloudFormation stack changeset\u001b[0m\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33mOperation                LogicalResourceId        ResourceType             Replacement            \u001b[0m\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33m* Modify                 RagAppApi                AWS::ApiGateway::RestA   False                  \u001b[0m\n",
      "\u001b[33m                                                  pi                                              \u001b[0m\n",
      "\u001b[33m* Modify                 RagAppFunction           AWS::Lambda::Function    False                  \u001b[0m\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "\n",
      "Changeset created successfully. arn:aws:cloudformation:eu-west-1:910416587115:changeSet/samcli-deploy1689587311/541962e9-d984-42c2-84d3-59c1b73feab3\n",
      "\n",
      "\n",
      "2023-07-17 12:48:43 - Waiting for stack create/update to complete\n",
      "\u001b[1m\n",
      "CloudFormation events from stack operations (refresh every 5.0 seconds)\u001b[0m\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33mResourceStatus           ResourceType             LogicalResourceId        ResourceStatusReason   \u001b[0m\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33mUPDATE_IN_PROGRESS       AWS::Lambda::Function    RagAppFunction           -                      \u001b[0m\n",
      "\u001b[32mUPDATE_COMPLETE          AWS::Lambda::Function    RagAppFunction           -                      \u001b[0m\n",
      "\u001b[33mUPDATE_COMPLETE_CLEANU   AWS::CloudFormation::S   gen-ai-immersion-day-    -                      \u001b[0m\n",
      "\u001b[33mP_IN_PROGRESS            tack                     stack                                           \u001b[0m\n",
      "\u001b[32mUPDATE_COMPLETE          AWS::CloudFormation::S   gen-ai-immersion-day-    -                      \u001b[0m\n",
      "\u001b[32m                         tack                     stack                                           \u001b[0m\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "\u001b[1mCloudFormation outputs from deployed stack\u001b[0m\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33mOutputs                                                                                         \u001b[0m\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32mKey                 ALBEndpoint                                                                 \u001b[0m\n",
      "\u001b[32mDescription         LoadBalancer DNS name                                                       \u001b[0m\n",
      "\u001b[32mValue               rag-load-balancer-117531014.eu-west-1.elb.amazonaws.com                     \u001b[0m\n",
      "\n",
      "\u001b[32mKey                 ALBDNSUrl                                                                   \u001b[0m\n",
      "\u001b[32mDescription         -                                                                           \u001b[0m\n",
      "\u001b[32mValue               http://rag-load-balancer-117531014.eu-west-1.elb.amazonaws.com              \u001b[0m\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "\n",
      "Successfully created/updated stack - gen-ai-immersion-day-stack in eu-west-1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sam deploy --stack-name gen-ai-immersion-day-stack --resolve-s3 --capabilities CAPABILITY_IAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"http://rag-load-balancer-117531014.eu-west-1.elb.amazonaws.com\"\n"
     ]
    }
   ],
   "source": [
    "!aws cloudformation describe-stacks --stack-name gen-ai-immersion-day-stack --query \"Stacks[0].Outputs[1].OutputValue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
